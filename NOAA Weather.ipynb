{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "id": "c2d6cf16-6bab-4eba-9630-5a38c92c0f23"
            },
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "Number of passed names did not match number of header fields in the file",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[3], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# of years: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m((data_weather\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m data_weather\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mdays\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m365\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     main()\n",
                        "Cell \u001b[0;32mIn[3], line 37\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m import_columns \u001b[38;5;241m=\u001b[39m [  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHOURLYVISIBILITY\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHOURLYDRYBULBTEMPF\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHOURLYPrecip\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHOURLYAltimeterSetting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Read data and set datetime index\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m data_weather \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATA_FILEPATH, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m], usecols\u001b[38;5;241m=\u001b[39mimport_columns)\n\u001b[1;32m     38\u001b[0m data_weather \u001b[38;5;241m=\u001b[39m data_weather\u001b[38;5;241m.\u001b[39mset_index(pd\u001b[38;5;241m.\u001b[39mDatetimeIndex(data_weather[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     39\u001b[0m data_weather\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
                        "File \u001b[0;32mparsers.pyx:579\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
                        "File \u001b[0;32mparsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: Number of passed names did not match number of header fields in the file"
                    ]
                }
            ],
            "source": "import sys\nimport numpy as np \nimport pandas as pd \nimport argparse \nparser = argparse.ArgumentParser(description='Cleans up NOAA weather data')\nparser.add_argument('-f', '--filepath', default='jfk_weather.csv', help='Filepath to NOAA weather data')\nparser.add_argument('-v', '--verbose', action='store_true', help='Print verbose')\nargs = parser.parse_args()\ndef tryconvert(value, dt=None):\n    \"\"\"\n    value -> Value to be converted\n    dt    -> data type to convert to (redundant for now)\n    \"\"\"\n    try:\n        return np.float64(value)\n    except:\n        return np.nan\n\ndef main():\n    DATA_FILEPATH = args.filepath\n    \n    import_columns = [  'DATE',\n                        'HOURLYVISIBILITY',\n                        'HOURLYDRYBULBTEMPF',\n                        'HOURLYWETBULBTEMPF',\n                        'HOURLYDewPointTempF',\n                        'HOURLYRelativeHumidity',\n                        'HOURLYWindSpeed',\n                        'HOURLYWindDirection',\n                        'HOURLYStationPressure',\n                        'HOURLYPressureTendency',\n                        'HOURLYSeaLevelPressure',\n                        'HOURLYPrecip',\n                        'HOURLYAltimeterSetting']\n    \n    # Read data and set datetime index\n    data_weather = pd.read_csv(DATA_FILEPATH, parse_dates=['DATE'], usecols=import_columns)\n    data_weather = data_weather.set_index(pd.DatetimeIndex(data_weather['DATE']))\n    data_weather.drop(['DATE'], axis=1, inplace=True)\n    \n    # Replace '*' values with np.nan\n    data_weather.replace(to_replace='*', value=np.nan, inplace=True)\n    # Replace trace amounts of precipitation with 0\n    data_weather['HOURLYPrecip'].replace(to_replace='T', value='0.00', inplace=True) \n    # Replace rows with tow '.' with np.nan\n    data_weather.loc[data_weather['HOURLYPrecip'].str.count('\\.') > 1, 'HOURLYPrecip'] = np.nan \n\n    # Convert to float\n    for i, _ in enumerate(data_weather.columns):\n        data_weather.iloc[:,i] =  data_weather.iloc[:,i].apply(lambda x: tryconvert(x))\n\n    # Replace any hourly visibility figure outside these 0-10 bounds\n    data_weather.loc[(data_weather['HOURLYVISIBILITY'] > 10) | (data_weather['HOURLYVISIBILITY'] < 0), 'HOURLYVISIBILITY'] = np.nan\n\n    # Downsample to hourly rows \n    data_weather = data_weather.resample('60min').last().shift(periods=1) \n\n    # Interpolate missing values\n    data_weather['HOURLYPressureTendency'] = data_weather['HOURLYPressureTendency'].fillna(method='ffill') #fill with last valid observation\n    data_weather = data_weather.interpolate(method='linear')\n    data_weather.drop(data_weather.index[0], inplace=True) #drop first row\n\n    # Transform HOURLYWindDirection into a cyclical variable using sin and cos transforms\n    data_weather['HOURLYWindDirectionSin'] = np.sin(data_weather['HOURLYWindDirection']*(2.*np.pi/360))\n    data_weather['HOURLYWindDirectionCos'] = np.cos(data_weather['HOURLYWindDirection']*(2.*np.pi/360))\n    data_weather.drop(['HOURLYWindDirection'], axis=1, inplace=True)\n\n    # Transform HOURLYPressureTendency into 3 dummy variables based on NOAA documentation\n    data_weather['HOURLYPressureTendencyIncr'] = [1.0 if x in [0,1,2,3] else 0.0 for x in data_weather['HOURLYPressureTendency']] # 0 through 3 indicates an increase in pressure over previous 3 hours\n    data_weather['HOURLYPressureTendencyDecr'] = [1.0 if x in [5,6,7,8] else 0.0 for x in data_weather['HOURLYPressureTendency']] # 5 through 8 indicates a decrease over the previous 3 hours\n    data_weather['HOURLYPressureTendencyCons'] = [1.0 if x == 4 else 0.0 for x in data_weather['HOURLYPressureTendency']] # 4 indicates no change during the previous 3 hours\n    data_weather.drop(['HOURLYPressureTendency'], axis=1, inplace=True)\n    data_weather['HOURLYPressureTendencyIncr'] = data_weather['HOURLYPressureTendencyIncr'].astype(('float32'))\n    data_weather['HOURLYPressureTendencyDecr'] = data_weather['HOURLYPressureTendencyDecr'].astype(('float32'))\n    data_weather['HOURLYPressureTendencyCons'] = data_weather['HOURLYPressureTendencyCons'].astype(('float32'))\n\n    # Output csv based on input filename\n    file_name, extension = args.filepath.split(\".\")\n    data_weather.to_csv(file_name +'_cleaned.csv', float_format='%g')\n\n    if args.verbose:\n        print(\"Data successfully cleaned, below are some stats:\")\n        print('# of megabytes held by dataframe: ' + str(round(sys.getsizeof(data_weather) / 1000000,2)))\n        print('# of features: ' + str(data_weather.shape[1])) \n        print('# of observations: ' + str(data_weather.shape[0]))\n        print('Start date: ' + str(data_weather.index[0]))\n        print('End date: ' + str(data_weather.index[-1]))\n        print('# of days: ' + str((data_weather.index[-1] - data_weather.index[0]).days))\n        print('# of months: ' + str(round((data_weather.index[-1] - data_weather.index[0]).days/30,2)))\n        print('# of years: ' + str(round((data_weather.index[-1] - data_weather.index[0]).days/365,2)))\n\nif __name__ == \"__main__\":\n    main()\n\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "6549f6b6-8678-4e9d-833a-e3f517eacd1c"
            },
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.11",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}